# AI Rails TDD Environment Configuration Example
# ================================================
# Copy this file to .env and fill in your values
# DO NOT commit .env to version control!

# =============================================================================
# LANGUAGE MODEL CONFIGURATION (Choose ONE option)
# =============================================================================

# -----------------------------------------------------------------------------
# OPTION 1: OpenAI API (Easiest Setup - Recommended for most users)
# -----------------------------------------------------------------------------
# Get your API key from: https://platform.openai.com/api-keys
# Costs: ~$0.01-0.03 per feature (GPT-3.5) or ~$0.10-0.30 per feature (GPT-4)
USE_OPENAI=true
OPENAI_API_KEY=sk-...your-key-here...
OPENAI_MODEL=gpt-4-turbo-preview  # Options: gpt-4-turbo-preview, gpt-3.5-turbo

# -----------------------------------------------------------------------------
# OPTION 2: Local Ollama (Free - Requires 16GB+ RAM)
# -----------------------------------------------------------------------------
# Install Ollama: https://ollama.ai
# Then run: ollama pull qwen2.5-coder:32b (or any other model)
# Note: First download will be ~20GB
USE_OLLAMA=false
OLLAMA_BASE_URL=http://localhost:11434  # Default Ollama port
OLLAMA_MODEL=qwen2.5-coder:32b  # Or: codellama, mistral, etc.

# -----------------------------------------------------------------------------
# OPTION 3: Remote Model Server (Advanced - If you have a GPU server)
# -----------------------------------------------------------------------------
# If you're running models on a separate machine (like a "workhorse")
USE_REMOTE_MODEL=false
REMOTE_MODEL_IP=192.168.1.100  # Replace with your server's IP
REMOTE_MODEL_PORT=11434  # Ollama default port
REMOTE_MODEL_URL=http://${REMOTE_MODEL_IP}:${REMOTE_MODEL_PORT}
REMOTE_MODEL_NAME=qwen2.5-coder:32b

# -----------------------------------------------------------------------------
# OPTION 4: Other Providers (Anthropic, Cohere, etc.)
# -----------------------------------------------------------------------------
# USE_ANTHROPIC=false
# ANTHROPIC_API_KEY=sk-ant-...your-key-here...
# ANTHROPIC_MODEL=claude-3-opus-20240229

# =============================================================================
# n8n CONFIGURATION (Required)
# =============================================================================
# n8n is the workflow automation tool that orchestrates the TDD process
# Install n8n: https://docs.n8n.io/hosting/installation/

# For local n8n installation
N8N_BASE_URL=http://localhost:5678  # Default n8n port

# If n8n is on a different machine
# N8N_BASE_URL=http://192.168.1.100:5678

# If using n8n cloud (https://n8n.io/cloud/)
# N8N_BASE_URL=https://your-instance.n8n.cloud
# N8N_API_KEY=your-n8n-api-key

# =============================================================================
# LOCAL SERVICES (AI Rails Components)
# =============================================================================

# Approval Server - Web UI for reviewing generated tests
APPROVAL_SERVER_PORT=8000
APPROVAL_SERVER_HOST=0.0.0.0  # Use localhost if only accessing locally

# Test Runner - Service that executes pytest
TEST_RUNNER_PORT=8001
TEST_RUNNER_HOST=0.0.0.0

# Webhook URLs (how n8n communicates with approval server)
# Note: If n8n is in Docker, use host.docker.internal instead of localhost
WEBHOOK_BASE_URL=http://localhost:8000
WEBHOOK_TIMEOUT=30  # seconds

# =============================================================================
# TEST & CODE GENERATION SETTINGS
# =============================================================================

# Temperature controls randomness (0.0 = deterministic, 1.0 = creative)
TEST_GENERATION_TEMPERATURE=0.7
CODE_GENERATION_TEMPERATURE=0.3

# Token limits (higher = more comprehensive but costs more with APIs, more energy with local models)
TEST_GENERATION_MAX_TOKENS=6000
CODE_GENERATION_MAX_TOKENS=8000

# Test execution settings
TEST_EXECUTION_TIMEOUT=30  # seconds per test file
MAX_TEST_RETRIES=3
PARALLEL_TEST_EXECUTION=false

# =============================================================================
# OPTIONAL: EXTERNAL SERVICE INTEGRATIONS
# =============================================================================

# GitHub Integration (for automatic PR creation)
# Create token at: https://github.com/settings/tokens
# GITHUB_TOKEN=ghp_...your-token-here...
# GITHUB_AUTO_BRANCH=true

# Redis (for production use with multiple users)
# REDIS_URL=redis://localhost:6379
# REDIS_DB=0
# REDIS_PASSWORD=your-redis-password

# =============================================================================
# OPTIONAL: MCP (Model Context Protocol) - Advanced
# =============================================================================
# MCP provides better codebase understanding
# See: docs/developer/mcp-integration.md for setup

# MCP_ENABLED=false
# CODEBASE_MCP_URL=http://localhost:8003
# SECRETS_MCP_URL=http://localhost:8005
# MCP_AUTH_TOKEN=your-mcp-token

# =============================================================================
# MCP API KEYS FOR AI RAILS PLANNING TEMPLATE
# =============================================================================
# These keys enable advanced research capabilities when using the planning template
# with Claude Code or other AI assistants. Keys are optional but highly recommended
# for comprehensive pre-implementation research.

# -----------------------------------------------------------------------------
# SEARCH PROVIDERS (via mcp-omnisearch)
# -----------------------------------------------------------------------------

# Tavily Search API - Factual queries with reliable sources
# Get key from: https://tavily.com/
# Free tier: 1000 queries/month
# TAVILY_API_KEY=tvly-...your-key-here...

# Brave Search API - Privacy-focused with advanced search operators
# Get key from: https://brave.com/search/api/
# Free tier: 2000 queries/month
# BRAVE_API_KEY=BSA...your-key-here...

# Kagi Search API - High-quality technical results, minimal SEO spam
# Get key from: https://kagi.com/api/
# Note: Subscription required, no free tier
# KAGI_API_KEY=...your-key-here...

# Perplexity API - AI-synthesized answers with reasoning
# Get key from: https://www.perplexity.ai/api
# Token-based pricing
# PERPLEXITY_API_KEY=pplx-...your-key-here...

# -----------------------------------------------------------------------------
# CONTENT PROCESSING
# -----------------------------------------------------------------------------

# Jina Reader API - Content extraction and fact-checking
# Get key from: https://jina.ai/reader/
# Free tier: Credits-based
# JINA_API_KEY=jina_...your-key-here...

# Firecrawl API - Dynamic content extraction for JavaScript-heavy sites
# Get key from: https://www.firecrawl.dev/
# Free tier: 500 pages/month
# FIRECRAWL_API_KEY=fc-...your-key-here...

# -----------------------------------------------------------------------------
# DOCUMENTATION RETRIEVAL (via context7)
# -----------------------------------------------------------------------------

# Upstash Vector Database - For storing and retrieving technical documentation
# Get both from: https://upstash.com/
# Free tier: 10,000 requests/day
# UPSTASH_VECTOR_URL=https://...upstash.io
# UPSTASH_VECTOR_TOKEN=...your-token-here...

# -----------------------------------------------------------------------------
# DEVELOPER RESOURCES
# -----------------------------------------------------------------------------

# Stack Exchange API - Better StackOverflow access (optional but recommended)
# Get key from: https://stackapps.com/apps/oauth/register
# Free tier with higher rate limits than anonymous access
# STACK_EXCHANGE_API_KEY=...your-key-here...

# =============================================================================
# LOGGING & MONITORING
# =============================================================================

# Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log file location (relative to your project's .ai-rails directory)
# This will create logs in: your-project/.ai-rails/logs/
LOG_FILE=.ai-rails/logs/ai-rails.log
LOG_TO_CONSOLE=true

# Production monitoring (optional)
# SENTRY_DSN=https://...@sentry.io/...
# ENABLE_METRICS=false

# =============================================================================
# FEATURE FLAGS
# =============================================================================

# Enable/disable features
ENABLE_PROPERTY_BASED_TESTING=true  # Hypothesis framework tests
ENABLE_SECURITY_TESTING=false  # Security vulnerability checks
ENABLE_PERFORMANCE_TESTING=false  # Performance benchmarks
ENABLE_MULTI_LANGUAGE_SUPPORT=false  # Support beyond Python

# =============================================================================
# PATHS (Usually auto-detected, override if needed)
# =============================================================================

# AI Rails installation directory (auto-detected from CLI location)
# AI_RAILS_HOME=/path/to/ai-rails-tdd

# Current project directory (auto-set when you run commands)
# PROJECT_PATH=/path/to/your/project